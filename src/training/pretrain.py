import torch
import torch.nn as nn  # NÃ©cessaire pour DataParallel
from torch.utils.data import DataLoader
import yaml
import os
from tqdm import tqdm

# Assurez-vous que les imports correspondent Ã  votre structure de dossiers
from src.models.contrastive import CrossModalContrastiveModel
from src.data.dataset import MMEADataset 

def load_config(config_path):
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def train_one_epoch(model, dataloader, optimizer, device):
    model.train()
    total_loss = 0
    
    # La barre de progression
    loop = tqdm(dataloader, desc="Training")
    
    for batch_idx, (imu, video) in enumerate(loop):
        # Envoi des donnÃ©es sur le GPU principal (DataParallel s'occupe de la distribution ensuite)
        imu = imu.to(device)
        video = video.to(device)
        
        optimizer.zero_grad()
        
        # --- Forward pass ---
        # Avec DataParallel, imu et video sont coupÃ©s en 2 (un morceau par GPU).
        # Le modÃ¨le s'exÃ©cute en parallÃ¨le.
        # Les rÃ©sultats (imu_feat, video_feat) sont rassemblÃ©s sur le GPU 0.
        imu_feat, video_feat = model(imu, video)
        
        # --- Calcul de la Loss ---
        # ATTENTION : DataParallel cache vos mÃ©thodes perso dans 'module'.
        # Il faut vÃ©rifier si le modÃ¨le est enveloppÃ© ou non.
        if isinstance(model, nn.DataParallel):
            loss = model.module.compute_loss(imu_feat, video_feat)
        else:
            loss = model.compute_loss(imu_feat, video_feat)
        
        # --- Backward ---
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        loop.set_postfix(loss=loss.item())
        
    return total_loss / len(dataloader)

def main():
    # 1. Chargement de la config
    cfg = load_config('configs/config.yaml')
    
    # 2. Configuration des GPUs pour Kaggle
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        device = torch.device('cuda')
        print(f"âœ… {num_gpus} GPU(s) dÃ©tectÃ©(s) !")
        if num_gpus > 1:
            print(f"   Les GPUs seront utilisÃ©s en parallÃ¨le : {[torch.cuda.get_device_name(i) for i in range(num_gpus)]}")
    else:
        device = torch.device('cpu')
        print("âš ï¸ Aucun GPU dÃ©tectÃ©. L'entraÃ®nement sera trÃ¨s lent.")

    # 3. PrÃ©paration des donnÃ©es
    # (Remplacez [] par votre logique de chargement de liste de fichiers)
    train_dataset = MMEADataset([], mode='pretrain', 
                                imu_params=cfg['preprocessing']['imu'],
                                video_params=cfg['preprocessing']['video'])
    
    # Optimisation pour Kaggle : num_workers=4 utilise les cÅ“urs CPU pour charger vite
    # pin_memory=True accÃ©lÃ¨re le transfert RAM -> VRAM
    train_loader = DataLoader(train_dataset, 
                              batch_size=cfg['training']['batch_size'], 
                              shuffle=True, 
                              num_workers=4,  
                              pin_memory=True)

    # 4. Initialisation du modÃ¨le
    print("Construction du modÃ¨le...")
    model = CrossModalContrastiveModel(cfg).to(device)
    
    # --- ACTIVATION MULTI-GPU ---
    if torch.cuda.device_count() > 1:
        print("ðŸš€ Activation de DataParallel pour utiliser les 2 GPUs...")
        model = nn.DataParallel(model)
    # ----------------------------

    # Optimiseur
    optimizer = torch.optim.AdamW(model.parameters(), 
                                  lr=float(cfg['training']['lr']), 
                                  weight_decay=1e-4)

    # 5. Boucle d'entraÃ®nement
    best_loss = float('inf')
    epochs = cfg['training']['epochs']
    
    print(f"DÃ©but de l'entraÃ®nement pour {epochs} Ã©poques.")
    
    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        
        loss = train_one_epoch(model, train_loader, optimizer, device)
        print(f"Average Loss: {loss:.4f}")
        
        # Sauvegarde du meilleur modÃ¨le
        if loss < best_loss:
            best_loss = loss
            
            # ASTUCE : Sauvegarder 'model.module' si DataParallel est utilisÃ©
            # Cela permet de recharger le modÃ¨le plus tard sur 1 seul GPU sans erreur de clÃ©s
            state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()
            
            torch.save(state_dict, "best_pretrained_model.pth")
            print("ðŸ’¾ ModÃ¨le sauvegardÃ© (format standard) !")

if __name__ == "__main__":
    main()